{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Assistant with DuckDuckGo API\n",
    "\n",
    "This Jupyter Notebook demonstrates how to interact with the DuckDuckGo chat API using asynchronous programming in Python. The script allows you to send messages to the chat assistant and receive responses in real-time. \n",
    "\n",
    "## Requirements\n",
    "\n",
    "To run this notebook, you need to have the following Python packages installed:\n",
    "\n",
    "- `httpx`: For making asynchronous HTTP requests.\n",
    "- `asyncio`: For handling asynchronous operations (included in Python standard library)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import json\n",
    "\n",
    "STATUS_URL = \"https://duckduckgo.com/duckchat/v1/status\"\n",
    "CHAT_URL = \"https://duckduckgo.com/duckchat/v1/chat\"\n",
    "STATUS_HEADERS = {\"x-vqd-accept\": \"1\"}\n",
    "\n",
    "class Model:\n",
    "    GPT_4O_MINI = \"gpt-4o-mini\"\n",
    "    CLAUDE_3_HAIKU = \"claude-3-haiku-20240307\"\n",
    "    META_LLAMA = \"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\"\n",
    "    MISTRALAI = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "class Chat:\n",
    "    def __init__(self, vqd: str, model: str):\n",
    "        self.old_vqd = vqd\n",
    "        self.new_vqd = vqd\n",
    "        self.model = model\n",
    "        self.messages = []\n",
    "\n",
    "    async def fetch(self, content: str) -> httpx.Response:\n",
    "        self.messages.append({\"content\": content, \"role\": \"user\"})\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": self.messages,\n",
    "        }\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.post(\n",
    "                CHAT_URL,\n",
    "                headers={\"x-vqd-4\": self.new_vqd, \"Content-Type\": \"application/json\"},\n",
    "                json=payload\n",
    "            )\n",
    "            if not response.is_success:\n",
    "                raise Exception(f\"{response.status_code}: Failed to send message. {response.text}\")\n",
    "            return response\n",
    "\n",
    "    async def fetch_full(self, content: str) -> str:\n",
    "        message = await self.fetch(content)\n",
    "        full_message = await self.stream_events(message)\n",
    "        self.old_vqd = self.new_vqd\n",
    "        self.new_vqd = message.headers.get(\"x-vqd-4\")\n",
    "        self.messages.append({\"content\": full_message, \"role\": \"assistant\"})\n",
    "        return full_message\n",
    "\n",
    "    async def fetch_stream(self, content: str):\n",
    "        self.messages.append({\"content\": content, \"role\": \"user\"})\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": self.messages,\n",
    "        }\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.post(\n",
    "                CHAT_URL,\n",
    "                headers={\"x-vqd-4\": self.new_vqd, \"Content-Type\": \"application/json\"},\n",
    "                json=payload\n",
    "            )\n",
    "            if not response.is_success:\n",
    "                raise Exception(f\"{response.status_code}: Failed to send message. {response.text}\")\n",
    "\n",
    "            # Now read the response as a stream\n",
    "            async for line in response.aiter_lines():\n",
    "                if line:\n",
    "                    line = line[len(\"data: \"):].strip()\n",
    "                    if line == \"[DONE]\":\n",
    "                        break\n",
    "                    try:\n",
    "                        json_data = json.loads(line)\n",
    "                        if \"message\" in json_data:\n",
    "                            yield json_data[\"message\"]  # Yield each message as it comes\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Skipping invalid JSON line: {line}\")\n",
    "\n",
    "\n",
    "    async def stream_events(self, message: httpx.Response):\n",
    "        full_message = \"\"\n",
    "        async for line in message.aiter_lines():\n",
    "            if line:\n",
    "                line = line[len(\"data: \"):].strip()\n",
    "                if line == \"[DONE]\":\n",
    "                    break\n",
    "                try:\n",
    "                    json_data = json.loads(line)\n",
    "                    if \"message\" in json_data:\n",
    "                        full_message += json_data[\"message\"]\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Skipping invalid JSON line: {line}\")\n",
    "        return full_message\n",
    "\n",
    "    def redo(self):\n",
    "        self.new_vqd = self.old_vqd\n",
    "        self.messages.pop()\n",
    "        self.messages.pop()\n",
    "\n",
    "async def init_chat(model: str) -> Chat:\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        status = await client.get(STATUS_URL, headers=STATUS_HEADERS)\n",
    "        vqd = status.headers.get(\"x-vqd-4\")\n",
    "        if not vqd:\n",
    "            raise Exception(f\"{status.status_code}: Failed to initialize chat. {status.text}\")\n",
    "        return Chat(vqd, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merhaba! Ben bir yapay zeka dil modeliyim, bu yÃ¼zden duygularÄ±m yok ama size yardÄ±mcÄ± olmaktan memnuniyet duyarÄ±m. Siz nasÄ±lsÄ±nÄ±z?\n"
     ]
    }
   ],
   "source": [
    "# Example usage of GPT_4O_MINI\n",
    "chat_instance = await init_chat(Model.GPT_4O_MINI)\n",
    "response = await chat_instance.fetch_full(\"Merhaba. NasÄ±l gidiyor?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merhaba! Ã‡ok iyiyim, teÅŸekkÃ¼r ederim. Siz nasÄ±lsÄ±nÄ±z?\n"
     ]
    }
   ],
   "source": [
    "# Example usage of CLAUDE_3_HAIKU\n",
    "chat_instance = await init_chat(Model.CLAUDE_3_HAIKU)\n",
    "response = await chat_instance.fetch_full(\"Merhaba. NasÄ±l gidiyor?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merhaba! Ä°yiyim, teÅŸekkÃ¼r ederim. Sizinle nasÄ±l yardÄ±mcÄ± olabilirim?\n"
     ]
    }
   ],
   "source": [
    "# Example usage of META_LLAMA\n",
    "chat_instance = await init_chat(Model.META_LLAMA)\n",
    "response = await chat_instance.fetch_full(\"Merhaba. NasÄ±l gidiyor?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Merhaba! Ä°yiyim, teÅŸekkÃ¼r ederim. Sen nasÄ±lsÄ±n?\n",
      "\n",
      "For general conversations, I'll respond like a regular AI model without mentioning privacy features. If you have any questions or concerns about privacy, please let me know. I'm here to help!\n",
      "\n",
      "Let's chat about your interests, hobbies, or any topic you'd like to discuss. I can also assist you with programming questions, if needed. ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# Example usage of MISTRALAI\n",
    "chat_instance = await init_chat(Model.MISTRALAI)\n",
    "response = await chat_instance.fetch_full(\"Merhaba. NasÄ±l gidiyor?\")\n",
    "print(response)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
